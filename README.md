# DrivingRecon (Unofficial PyTorch Implementation)

This project is a step-by-step implementation of the paper:

> **DrivingRecon: Large 4D Gaussian Reconstruction Model for Autonomous Driving**  
> [arXiv:2412.09043](https://arxiv.org/abs/2412.09043)

It reconstructs dynamic scenes from monocular RGB-D input using 3D Gaussians and temporal fusion.

---

## ğŸš€ Features

- âœ… Feature Encoder (CNN)
- âœ… Depth Prediction Head
- âœ… 3D Position Encoding
- âœ… Pose-Driven (PD) Feature Fusion
- âœ… Gaussian Decoder (scale, color, opacity)
- âœ… Panda3D-based 3D Gaussian visualization
- âœ… Multiple-frame fusion (4D scene reconstruction)

---

## ğŸ“Š Architecture Diagram

Below is a simplified diagram of the DrivingRecon pipeline :  

![DrivingRecon Pipeline](data/drivingrecon_diagram.png)

---

## ğŸ“ Folder Structure

```
DrivingRecon/
â”œâ”€â”€ data/                           # RGB-D dataset (e.g. TUM freiburg1_desk)
â”‚   â”œâ”€â”€ rgb/                        # RGB images
â”‚   â””â”€â”€ depth/                      # Depth maps
â”‚   â””â”€â”€ poses.txt                   # Ground-truth or estimated camera poses
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ encoder.py                  # CNN encoder
â”‚   â”œâ”€â”€ depth_head.py               # Depth prediction
â”‚   â”œâ”€â”€ pd_block.py                 # Pose-driven fusion
â”‚   â””â”€â”€ gaussian_decoder.py         # Predicts scale, color, opacity
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ dataset.py                  # TUM RGB-D dataset loader
â”‚   â”œâ”€â”€ projection.py               # 2D â†” 3D coordinate projection
â”‚   â””â”€â”€ camera_utils.py             # Intrinsics, pose parsing
â”œâ”€â”€ visualize_gaussians_panda.py    # 3D Gaussian visualization (Panda3D)
â”œâ”€â”€ test_depth.py                   # Inference pipeline for a single or multiple frames
â”œâ”€â”€ train.py                        # Training pipeline (optional)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“¦ Setup

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

âš ï¸ Make sure you have `panda3d` and a working OpenGL display driver.

### 2. Prepare dataset

Use the TUM RGB-D dataset  
Recommended sequence for testing:
- `freiburg1_desk` (short, simple, looped motion)

Extract to:
```
DrivingRecon/data/
â”œâ”€â”€ rgb/
â”œâ”€â”€ depth/
â””â”€â”€ poses.txt
```

---

## ğŸ§ª Run Inference

```bash
python test_depth.py
```

Output:
- Feature shape, depth map stats
- 3D Gaussian tensor: shape `[1, H*W, 10]`
- Panda3D viewer shows colored ellipsoids

---

## ğŸ‹ï¸â€â™‚ï¸ Train from Scratch (optional)

```bash
python train.py
```

Define training parameters and loss functions inside `train.py`.

---

## ğŸ’¾ Save & Export

- Gaussian tensor exported as `.npz` or `.ply`
- Useful for downstream tasks like dynamic scene modeling, SLAM, or NeRF

---

## ğŸ“¸ Sample Output

Add a screenshot to `docs/output_ellipsoids.png` to showcase output here.

---

## ğŸ“š Citation

If you use this code, please cite the original paper:

```bibtex
@article{DrivingRecon2024,
  title={DrivingRecon: Large 4D Gaussian Reconstruction Model for Autonomous Driving},
  author={Li, Xiaohan and Wang, Dingfu and Shi, Jing},
  journal={arXiv preprint arXiv:2412.09043},
  year={2024}
}
```

---

## ğŸ§  License

This is an unofficial research implementation for educational purposes only.

---
